{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exploration.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMunr9Tp4SK9Ck668gsqmL1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fcolombo7/AN2DL-2020/blob/main/Exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kv5ltS4h5bUx"
      },
      "source": [
        "# Exploration of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOlVyQ0Q4_9X",
        "outputId": "2722747b-8f48-4e43-fb9f-a5902c462eb1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M-VTLnC5i-3"
      },
      "source": [
        "import os\n",
        "from zipfile import ZipFile\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/ANN_project2/starting_kit')\n",
        "\n",
        "import prepare_submission\n",
        "import read_mask_example\n",
        "import decode_rle_example\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCA2BTj_6PTe"
      },
      "source": [
        "# Set the seed for random operations. \n",
        "SEED = 1234\n",
        "tf.random.set_seed(SEED)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_9aZFuE6YTK"
      },
      "source": [
        "#Definitions of constants\n",
        "apply_data_augmentation = True"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUpdaMNh52CT"
      },
      "source": [
        "## Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lVNqdheK_hm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ff298d1-1681-4a04-9f23-0f16d945964a"
      },
      "source": [
        "if not os.path.exists('Development_Dataset'):\n",
        "  with ZipFile('./drive/MyDrive/ANN_project2/dataset.zip', 'r') as zipObj:\n",
        "    # Extract all the contents of zip file in current directory\n",
        "    zipObj.extractall()\n",
        "print('The dataset is loaded.')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The dataset is loaded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6atE3k09ThP"
      },
      "source": [
        "Check properties of the images such as the number of training samples and the shapes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZudJ4jzw_h-3"
      },
      "source": [
        "cwd = os.getcwd()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9U-MX1y6FGQ",
        "outputId": "30d18843-f072-4d4f-c4dc-9599554061c1"
      },
      "source": [
        "import pathlib\n",
        "path = os.path.join(cwd, 'Development_Dataset', 'Training', 'Bipbip') \n",
        "data_dir = pathlib.Path(path)\n",
        "training_images_h = list(data_dir.glob('Haricot/Images/*'))\n",
        "training_images_m = list(data_dir.glob('Mais/Images/*')) \n",
        "training_masks_h = list(data_dir.glob('Haricot/Masks/*'))\n",
        "training_masks_m = list(data_dir.glob('Haricot/Masks/*'))\n",
        "\n",
        "print(f\"number of haricot images: {len(training_images_h)}\")\n",
        "print(f\"number of mais images: {len(training_images_m)}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of haricot images: 90\n",
            "number of mais images: 90\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nObpcGZd_qU9",
        "outputId": "73211cb2-a344-4f09-b7a1-bccfc0d97777"
      },
      "source": [
        "import PIL\n",
        "\n",
        "image_sizes = set() #unique sizes\n",
        "for image in training_images_h+training_images_m:\n",
        "  image_sizes.add(PIL.Image.open(str(image)).size)\n",
        "print(f\"number of unique sizes: {len(image_sizes)}\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of unique sizes: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PIEJL5m__q9",
        "outputId": "8d0ceaee-f962-4820-f3ac-c3db9d455642"
      },
      "source": [
        "print(f'input shape: {PIL.Image.open(str(training_images_h[0])).size}')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input shape: (2048, 1536)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUjsR9jND14t"
      },
      "source": [
        "Define the `ImageDataGenerator`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzE_qrgwAPjm"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "if apply_data_augmentation:\n",
        "    img_data_gen = ImageDataGenerator(rotation_range=10,\n",
        "                                      width_shift_range=10,\n",
        "                                      height_shift_range=10,\n",
        "                                      zoom_range=0.3,\n",
        "                                      horizontal_flip=True,\n",
        "                                      vertical_flip=True,\n",
        "                                      fill_mode='reflect')\n",
        "    mask_data_gen = ImageDataGenerator(rotation_range=10,\n",
        "                                       width_shift_range=10,\n",
        "                                       height_shift_range=10,\n",
        "                                       zoom_range=0.3,\n",
        "                                       horizontal_flip=True,\n",
        "                                       vertical_flip=True,\n",
        "                                       fill_mode='reflect')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsieZk4aKhm6"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "class CustomDataset(tf.keras.utils.Sequence):\n",
        "\n",
        "  \"\"\"\n",
        "    CustomDataset inheriting from tf.keras.utils.Sequence.\n",
        "\n",
        "    3 main methods:\n",
        "      - __init__: save dataset params like directory, filenames..\n",
        "      - __len__: return the total number of samples in the dataset\n",
        "      - __getitem__: return a sample from the dataset\n",
        "\n",
        "    Note: \n",
        "      - the custom dataset return a single sample from the dataset. Then, we use \n",
        "        a tf.data.Dataset object to group samples into batches.\n",
        "      - in this case we have a different structure of the dataset in memory. \n",
        "        We have all the images in the same folder and the training and validation splits\n",
        "        are defined in text files.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, dataset_dir, which_subset, img_generator=None, mask_generator=None, \n",
        "               preprocessing_function=None, out_shape=[256, 256]):\n",
        "    if which_subset == 'training':\n",
        "      subset_file = os.path.join(dataset_dir, 'Splits', 'train.txt')\n",
        "    elif which_subset == 'validation':\n",
        "      subset_file = os.path.join(dataset_dir, 'Splits', 'val.txt')\n",
        "    \n",
        "    with open(subset_file, 'r') as f:\n",
        "      lines = f.readlines()\n",
        "    \n",
        "    subset_filenames = []\n",
        "    for line in lines:\n",
        "      subset_filenames.append(line.strip()) \n",
        "\n",
        "    self.which_subset = which_subset\n",
        "    self.dataset_dir = dataset_dir\n",
        "    self.subset_filenames = subset_filenames\n",
        "    self.img_generator = img_generator\n",
        "    self.mask_generator = mask_generator\n",
        "    self.preprocessing_function = preprocessing_function\n",
        "    self.out_shape = out_shape\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.subset_filenames)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    # Read Image\n",
        "    curr_filename = self.subset_filenames[index]\n",
        "    img = Image.open(os.path.join(self.dataset_dir, 'Images', curr_filename + '.jpg'))\n",
        "    mask = Image.open(os.path.join(self.dataset_dir, 'Annotations', curr_filename + '.png'))\n",
        "\n",
        "    # Resize image and mask\n",
        "    img = img.resize(self.out_shape)\n",
        "    mask = mask.resize(self.out_shape, resample=Image.NEAREST)\n",
        "    \n",
        "    img_arr = np.array(img)\n",
        "    mask_arr = np.array(mask)\n",
        "\n",
        "    # in this dataset 255 mask label is assigned to an additional class, which corresponds \n",
        "    # to the contours of the objects. We remove it for simplicity.\n",
        "    mask_arr[mask_arr == 255] = 0  \n",
        "\n",
        "    mask_arr = np.expand_dims(mask_arr, -1)\n",
        "\n",
        "    if self.which_subset == 'training':\n",
        "      if self.img_generator is not None and self.mask_generator is not None:\n",
        "        # Perform data augmentation\n",
        "        # We can get a random transformation from the ImageDataGenerator using get_random_transform\n",
        "        # and we can apply it to the image using apply_transform\n",
        "        img_t = self.img_generator.get_random_transform(img_arr.shape, seed=SEED)\n",
        "        mask_t = self.mask_generator.get_random_transform(mask_arr.shape, seed=SEED)\n",
        "        img_arr = self.img_generator.apply_transform(img_arr, img_t)\n",
        "        # ImageDataGenerator use bilinear interpolation for augmenting the images.\n",
        "        # Thus, when applied to the masks it will output 'interpolated classes', which\n",
        "        # is an unwanted behaviour. As a trick, we can transform each class mask \n",
        "        # separately and then we can cast to integer values (as in the binary segmentation notebook).\n",
        "        # Finally, we merge the augmented binary masks to obtain the final segmentation mask.\n",
        "        out_mask = np.zeros_like(mask_arr)\n",
        "        for c in np.unique(mask_arr):\n",
        "          if c > 0:\n",
        "            curr_class_arr = np.float32(mask_arr == c)\n",
        "            curr_class_arr = self.mask_generator.apply_transform(curr_class_arr, mask_t)\n",
        "            # from [0, 1] to {0, 1}\n",
        "            curr_class_arr = np.uint8(curr_class_arr)\n",
        "            # recover original class\n",
        "            curr_class_arr = curr_class_arr * c \n",
        "            out_mask += curr_class_arr\n",
        "    else:\n",
        "      out_mask = mask_arr\n",
        "    \n",
        "    if self.preprocessing_function is not None:\n",
        "        img_arr = self.preprocessing_function(img_arr)\n",
        "\n",
        "    return img_arr, np.float32(out_mask)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}