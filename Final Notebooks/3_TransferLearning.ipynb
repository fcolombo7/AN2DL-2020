{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3-TransferLearning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fcolombo7/AN2DL-2020/blob/main/Final%20Notebooks/3_TransferLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyGfDyE8MEyZ"
      },
      "source": [
        "# **AN2DL** - Image classification challenge\n",
        "\n",
        "* **Colombo Filippo** - 10559531\n",
        "* **Del Vecchio** Giovanni - 10570682\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URPWyV4iMQYv"
      },
      "source": [
        "## Model with transfer learning\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCwx6rVCMdGI"
      },
      "source": [
        "Configuration and constants:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2Mzov4HfF2U"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-4aT9zgG0oe"
      },
      "source": [
        "#Random seed to make experiments reproducible\n",
        "SEED = 1234\n",
        "tf.random.set_seed(SEED)  \n",
        "\n",
        "#Parameters\n",
        "IMG_H, IMG_W = (400, 400)\n",
        "BS = 32 #BATCH SIZE\n",
        "VALIDATION_SPLIT = 0.2\n",
        "DATA_AUGMENTATION = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUOZsQODNCK4"
      },
      "source": [
        "Load Google Drive to get the data and save the results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZp3vyhvG8KO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bd4eb04-769d-442c-f1f8-337756d8300b"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "cwd = os.getcwd()\n",
        "drive_root_folder = '/content/drive/My Drive/ANN_project/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_50jGtxNa-0"
      },
      "source": [
        "### Import the Mask Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipFiRLDRKh1e"
      },
      "source": [
        "Check if the dataset has been already processed, otherwise unzip it.\n",
        "\n",
        "**N.B.**: we are unzipping in the `/content` folder and not in `drive`.  \n",
        "If you want to unzip in your drive folder, write `os.chdir(drive_root_folder)`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHDb6talfR-t"
      },
      "source": [
        "#check if the dataset is already available\n",
        "if not os.path.exists(cwd+'/MaskDataset'):\n",
        "  !unzip '/content/drive/My Drive/ANN_project/artificial-neural-networks-and-deep-learning-2020.zip'\n",
        "else:\n",
        "  print('MaskDataset already loaded')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUNMDIj2O3kw"
      },
      "source": [
        "### Split the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlzyOqrMRfH0"
      },
      "source": [
        "Definition of the `ImageDataGenerator` for _data augmentation_:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODKLCXMJhFnu"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "if DATA_AUGMENTATION:\n",
        "    train_data_gen = ImageDataGenerator(rotation_range=20, \n",
        "                                        width_shift_range=0.3, \n",
        "                                        height_shift_range=0.3, \n",
        "                                        zoom_range=0.4, \n",
        "                                        horizontal_flip=True, #\n",
        "                                        #brightness_range = [0.6, 1.5], \n",
        "                                        shear_range=10, \n",
        "                                        channel_shift_range=100, \n",
        "                                        fill_mode='reflect', \n",
        "                                        rescale=1./255)\n",
        "else:\n",
        "    train_data_gen = ImageDataGenerator(rescale=1./255)\n",
        "    \n",
        "valid_data_gen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YQh2TsygS-r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f8ef604-037c-442b-c862-17128bcc5dfe"
      },
      "source": [
        "import json\n",
        "\n",
        "dataset_dir = os.path.join(cwd, \"MaskDataset\")\n",
        "training_dir = os.path.join(dataset_dir, \"training\")\n",
        "with open(os.path.join(dataset_dir,\"train_gt.json\")) as f:\n",
        "  dic = json.load(f)\n",
        "  dataframe = pd.DataFrame(dic.items())\n",
        "  dataframe.rename(columns = {0:'filename', 1:'class'}, inplace = True)\n",
        "  dataframe = dataframe.sample(frac=1, random_state=SEED)\n",
        "  \n",
        "  tot_length = dataframe.shape[0]\n",
        "  valid = dataframe.iloc[:int(np.ceil(tot_length * VALIDATION_SPLIT)),:] \n",
        "  train = dataframe.iloc[int(np.ceil(tot_length * VALIDATION_SPLIT)):,:]\n",
        "  train[\"class\"] = train[\"class\"].astype('string')\n",
        "  valid[\"class\"] = valid[\"class\"].astype('string')\n",
        "  \n",
        "  train_gen = train_data_gen.flow_from_dataframe(train,\n",
        "                                               training_dir,\n",
        "                                               batch_size=BS,\n",
        "                                               target_size=(IMG_H, IMG_W),\n",
        "                                               class_mode='categorical',\n",
        "                                               shuffle=True,\n",
        "                                               seed=SEED)\n",
        "  \n",
        "  validation_gen = valid_data_gen.flow_from_dataframe(valid,\n",
        "                                               training_dir,\n",
        "                                               batch_size=BS,\n",
        "                                               target_size=(IMG_H, IMG_W),\n",
        "                                               class_mode='categorical',\n",
        "                                               shuffle=True,\n",
        "                                               seed=SEED)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4491 validated image filenames belonging to 3 classes.\n",
            "Found 1123 validated image filenames belonging to 3 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bgWDFVZeeNx"
      },
      "source": [
        "### Build the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3JF94cte4zX"
      },
      "source": [
        "#### Create the dataset objects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jwtQWEn1SXz"
      },
      "source": [
        "num_classes = len(train_gen.class_indices)\n",
        "num_classes\n",
        "train_ds = tf.data.Dataset.from_generator(lambda: train_gen, \n",
        "                                          output_types=(tf.float32, tf.float32),\n",
        "                                          output_shapes= ([None, IMG_H, IMG_W, 3], [None, num_classes]))\n",
        "\n",
        "train_ds = train_ds.repeat()\n",
        "\n",
        "valid_ds = tf.data.Dataset.from_generator(lambda: validation_gen,\n",
        "                                          output_types = (tf.float32, tf.float32),\n",
        "                                          output_shapes = ([None, IMG_H, IMG_W, 3], [None, num_classes]))\n",
        "valid_ds = valid_ds.repeat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GxO1cGCQ3xE"
      },
      "source": [
        "####Use a pretrainde network as strating point: **VGG16**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyXUYanoQ53S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe1cb917-4b7e-44bb-8102-246cd5ddeb94"
      },
      "source": [
        "base_model = tf.keras.applications.VGG16(include_top=False, weights='imagenet', input_shape=(IMG_H,IMG_W,3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "p_Sw7OA30Ots",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "135972bc-68e3-4fc7-b50b-0e897e00d256"
      },
      "source": [
        "base_model.trainable = False\n",
        "      \n",
        "model = tf.keras.Sequential()\n",
        "model.add(base_model)\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(units=448, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.1))\n",
        "model.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Functional)           (None, 12, 12, 512)       14714688  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 73728)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 448)               33030592  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 448)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 1347      \n",
            "=================================================================\n",
            "Total params: 47,746,627\n",
            "Trainable params: 33,031,939\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URZq-McI5oqC"
      },
      "source": [
        "### Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKAwwLIgmxQ4"
      },
      "source": [
        "def get_optimizer(lr_schedule = 1e-3):\n",
        "  return tf.keras.optimizers.Adam(learning_rate=lr_schedule)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HCbyUgxg_uC"
      },
      "source": [
        "def get_callbacks(name, es=True, patience = 10):\n",
        "  obj = []\n",
        "\n",
        "  exps_dir = os.path.join(drive_root_folder,'classification_result')\n",
        "  if not os.path.exists(exps_dir):\n",
        "    os.mkdir(exps_dir)\n",
        "\n",
        "  now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
        "  temp_dir = name +'_'+ now\n",
        "\n",
        "  #Model Checkpoints\n",
        "  ckpt_dir = os.path.join(exps_dir, temp_dir, 'ckpts')\n",
        "  if not os.path.exists(ckpt_dir):\n",
        "    os.makedirs(ckpt_dir)\n",
        "\n",
        "  obj.append(tf.keras.callbacks.ModelCheckpoint(filepath = os.path.join(ckpt_dir, 'cp.ckpt'),\n",
        "                                                save_weights_only = True,\n",
        "                                                save_best_only = True))\n",
        "  \n",
        "  #Tensor board logs\n",
        "  tb_dir = os.path.join(exps_dir, temp_dir + '/tb_logs')\n",
        "  if not os.path.exists(tb_dir):\n",
        "    os.makedirs(tb_dir)\n",
        "  obj.append(tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n",
        "                                            profile_batch = 0,\n",
        "                                            histogram_freq = 1))\n",
        "  if es:\n",
        "    obj.append(tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = patience))\n",
        "\n",
        "  return obj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7q2E_I86wWK"
      },
      "source": [
        "name = 'VGG-U448-DO01'\n",
        "model.compile(optimizer=get_optimizer(),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x=train_ds,\n",
        "          epochs=40,\n",
        "          steps_per_epoch=len(train_gen),\n",
        "          validation_data=valid_ds,\n",
        "          validation_steps=len(validation_gen), \n",
        "          callbacks=get_callbacks(name),\n",
        "          verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7XT_pJ0V1ZT"
      },
      "source": [
        "### Load the best model according to the checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwcdESkdXNFe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4481820-60b1-4f26-c1b8-de0e588b1a2d"
      },
      "source": [
        "model_to_load = 'VGG-U448-DO01' #check the model name in the drive folder (the time stamp changes)\n",
        "ckpt_path = os.path.join(drive_root_folder,'classification_result',model_to_load, 'ckpts','cp.ckpt')\n",
        "model.load_weights(ckpt_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f49301b9dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTIuwKfeLN9a"
      },
      "source": [
        "### Fine-tuning of the entire model\n",
        "Unfreeze the base model and train the entire model end-to-end with a low learning rate.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ffbq_2VA75Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a347c48e-e91e-4a6f-cf9c-b154260f5281"
      },
      "source": [
        "base_model.trainable = True\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Functional)           (None, 12, 12, 512)       14714688  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 73728)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 448)               33030592  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 448)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 1347      \n",
            "=================================================================\n",
            "Total params: 47,746,627\n",
            "Trainable params: 47,746,627\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cc299505b72"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-5),  # Low learning rate\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "epochs = 20\n",
        "model.fit(train_ds,\n",
        "          epochs=epochs,\n",
        "          validation_data=valid_ds,\n",
        "          steps_per_epoch = len(train_gen),\n",
        "          validation_steps = len(validation_gen),\n",
        "          callbacks=get_callbacks('FT-'+model_to_laod, es = True, patience=8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pi5B6RK5b52M"
      },
      "source": [
        "## Predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWNWkCg5cjsh"
      },
      "source": [
        "First load the test images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPFPEMYHeZCI"
      },
      "source": [
        "import pathlib\n",
        "path = os.path.join(os.getcwd(),'MaskDataset', 'test')\n",
        "data_dir = pathlib.Path(path)\n",
        "\n",
        "test_image_filenames = list(data_dir.glob('*.jpg'))\n",
        "len(test_image_filenames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26uSROvwXlKR"
      },
      "source": [
        "test_normalization = tf.keras.Sequential([\n",
        "                                       tf.keras.layers.experimental.preprocessing.Rescaling(1./255)                 \n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1MZJxvKlG9D"
      },
      "source": [
        "def make_prediction():\n",
        "  results = {}\n",
        "  results_expanded = {}\n",
        "  for test_image in test_image_filenames:\n",
        "    img = tf.keras.preprocessing.image.load_img(test_image, target_size=(IMG_H, IMG_W))\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
        "\n",
        "    normalized_img = test_normalization(img_array, training=True)\n",
        "    predictions = model.predict(normalized_img)\n",
        "    results_expanded[os.path.basename(test_image)]=predictions\n",
        "    results[os.path.basename(test_image)]=np.argmax(predictions)\n",
        "  return results, results_expanded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYXxxXNOkHdO"
      },
      "source": [
        "def create_csv(results, results_dir):\n",
        "    csv_fname = 'results_'\n",
        "    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
        "\n",
        "    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n",
        "        f.write('Id,Category\\n')\n",
        "        for key, value in results.items():\n",
        "            f.write(key + ',' + str(value) + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8_2J8skkajW"
      },
      "source": [
        "create_csv(make_prediction()[0], drive_root_folder)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}